---
title: "Skull Stripping and Registration of Head CT Data"
output:
  pdf_document:
    keep_tex: false
  html_document:
    keep_md: yes
    code_download: true    
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
bibliography: refs.bib
---


```{r setup, include=FALSE}
library(dcm2niir)
library(ichseg)
library(fslr)
library(extrantsr)
library(TCIApathfinder)
knitr::opts_chunk$set(echo = TRUE, comment = "")
```


# Goal
In this tutorial, we will discuss skull-stripping (or brain-extracting) X-ray computed tomography (CT) scans.  We will use data from TCIA (http://www.cancerimagingarchive.net/).  The entire pipeline goes from raw DICOM data, converts it to NIfTI images, performs brain extraction, and then spatially normalizes the brain to a template using non-linear registration.  All of the packages are open source and are available through [CRAN](https://cran.r-project.org/) or [Neuroconductor (https://neuroconductor.org/)](https://neuroconductor.org/) for the R programming language.  We extract data from TCIA from the [`TCIApathfinder`](https://CRAN.R-project.org/package=TCIApathfinder) R package.

## Installing Packages

In order to run all the code in this tutorial, these packages need to be installed.  The following code should install all the packages. 

```{r, eval = FALSE}
install.packages(c("TCIApathfinder", "dplyr"))
source("https://neuroconductor.org/neurocLite.R") 
neuro_install(c("dcm2niir", "ichseg", "fslr", "extrantsr"))
```



## Using TCIApathfinder

In order to use `TCIApathfinder`, please see the [vignette to obtain API keys](https://cran.r-project.org/web/packages/TCIApathfinder/vignettes/introduction.html) [@TCIApathfinder].  Here we will look at the collections of data available given the code below:

```{r}
library(TCIApathfinder)
series_instance_uid = "1.3.6.1.4.1.14519.5.2.1.2857.3707.893926543922125108620513439908"
download_unzip_series = function(series_instance_uid,
                                 verbose = TRUE) {
  tdir = tempfile()
  dir.create(tdir, recursive = TRUE)
  tfile = tempfile(fileext = ".zip")
  tfile = basename(tfile)
  if (verbose) {
    message("Downloading Series")
  }
  res = save_image_series(
    series_instance_uid = series_instance_uid, 
    out_dir = tdir, 
    out_file_name = tfile)
  if (verbose) {
    message("Unzipping Series")
  }  
  stopifnot(file.exists(res$out_file))
  tdir = tempfile()
  dir.create(tdir, recursive = TRUE)
  res = unzip(zipfile = res$out_file, exdir = tdir)
  L = list(files = res,
           dirs = unique(dirname(normalizePath(res))))
  return(L)
}
# Download and unzip the image series

file_list = download_unzip_series(
  series_instance_uid = series_instance_uid)
```

Here we extracted a single series of a CT brain scan.  The data are in DICOM format.

## Converting DICOM to NIfTI

We will use [`dcm2niix`](https://github.com/rordenlab/dcm2niix) to convert the data from DICOM to NIfTI.  The function `dcm2niix` is wrapped in the `dcm2niir` R package [@dcm2niir].  We will use `dcm2niir::dcm2nii` to convert the file.  We use `check_dcm2nii` to grab the relevant output files:
 
```{r}
library(dcm2niir)
dcm_result = dcm2nii(file_list$dirs)
dcm_result$nii_after
result = check_dcm2nii(dcm_result)
result
```
Here we see the output is a single NIfTI file.  If there is any gantry tilt or variable slice thickness, `dcm2niix` has accounted for this.  We also see an associated `json` file, which is a BIDS sidecar file.

We can show the `json` file by using `jsonlite::fromJSON`:
```{r}
json = jsonlite::fromJSON(attr(result, "json_file"))
names(json)
```
where we see a lot of the information necessary for reporting are given.  

Next we read the data into `R` into a `nifti` object:
```{r}
library(neurobase)
img = readnii(result)
ortho2(img)
range(img)
```

Here we will use `neurobase::rescale_img` to make sure the minimum is $-1024$ and the maximum is $3071$.  The minimum can be lower for areas outside the field of view (FOV).  Here we plot the image and the Winsorized version to see the brain tissue:

```{r}
img = rescale_img(img, min.val = -1024, max.val = 3071)
ortho2(img)
ortho2(img, window = c(0, 100))
```

We see the image has high resolution within the axial plane, but not as high resolution in the sagittal plane.  We see high values in the skull and other dense areas and lower values within the brain and the darkest values outside of the head.


## Skull Strip

We can skull strip the image using `CT_Skull_Strip` or `CT_Skull_Stripper` from the `ichseg` R package.  The `CT_Skull_Stripper` has a simple switch to use `CT_Skull_Strip` or `CT_Skull_Strip_robust` [@ichseg].  
```{r}
library(ichseg)
ss = CT_Skull_Strip(img, verbose = FALSE)
ortho2(img, ss > 0, 
       window = c(0, 100),
       col.y = scales::alpha("red", 0.5))
```

The `CT_Skull_Strip_robust` function does 2 neck removals using `remove_neck` from `extrantsr` and then find the center of gravity (COG) twice to make sure the segmentation focuses on the head, which uses some FSL [@fsl] functions in the `fslr` package [@fslr].  In some instances, the whole neck is included in the scan, such as some of the head-neck studies in TCIA.


## (Optional) Defacing the Image

If you have [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) installed, in the `fslr` R package version (>= 2.23.0), the `deface_image` function should allow for defacing of the image [@fsl; @fslr].  The defacing can be a part of a de-identification protocol to aim for HIPAA compliance:

```{r}
noface_file = fslr::deface_image(img + 1024, template = NULL, face_mask = NULL)
noface = readnii(noface_file)
noface = noface - 1024
ortho2(noface)
```

We see that the face has been removed from the image.  If you want the mask instead of the image with the face removed, you can run `fslr::face_removal_mask`.  Alternatively, the `ichseg::ct_biometric_mask` function should try to get masks of the face and ears, running the `ichseg::ct_face_mask` and `ichseg::ct_ear_mask` functions and combining them into one mask.  You can then either remove those areas, randomize the voxels (not recommended), or put a heavy smoother over the area. 


### Defacing using Quickshear method
If you have the `fslr` package 2.23.1 or above, the `quickshear` method [@quickshear] has been implemented.  This is different from the `deface_image` above, but requires a brain mask.  

```{r}
qs_noface = fslr::quickshear_deface_image(file = img, brain_mask = ss > 0)
ortho2(qs_noface)
```



## Registration

Here we register the image to the template image from Rorden (2012).  We will use the `registration` function from the `extrantsr` R package [@extrantsr].  The `extrantsr` package uses the `ANTsR` R package to perform the registration, and simply wraps multiple commands together [@ANTsR].  We will use a Symmetric Normalization (SyN) type of registration, which first uses an affine registration, then combines it with a symmetric non-linear diffeomorphism.  The output file `reg$outfile` is the registered image.

```{r}
template_image = ichseg::ct_template(type = "image")
ortho2(template_image, window = c(0, 100))
reg = extrantsr::registration(
  img, template.file = template_image, 
  typeofTransform = "SyN", 
  interpolator = "Linear")
wimg = window_img(reg$outfile, window = c(0, 100))
double_ortho(template_image, wimg, window = c(0, 100))
```
We see relatively good alignment between the template image (left) and the registered image (right)

Here we will use the skull-stripped template and perform the same registration with the skull-stripped image.  
```{r}
template_brain = ichseg::ct_template(type = "brain")
ortho2(template_brain, window = c(0, 100))
brain_reg = extrantsr::registration(
  ss, template.file = template_brain, 
  typeofTransform = "SyN", 
  interpolator = "Linear")
wbrain = window_img(brain_reg$outfile, window = c(0, 100))
double_ortho(template_image, wbrain, window = c(0, 100))
```

We see again good alignment, but we see that there are some stark differences in these registrations when we compare them:

```{r}
double_ortho(wimg, wbrain)
```
